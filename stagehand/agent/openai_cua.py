import asyncio
import json
import os
import re
from typing import Any, Optional

from dotenv import load_dotenv
from openai import OpenAI as OpenAISDK

from ..handlers.cua_handler import CUAHandler
from ..types.agent import (
    ActionExecutionResult,
    AgentAction,
    AgentActionType,
    AgentConfig,
    AgentExecuteOptions,
    AgentResult,
    FunctionAction,
)
from .client import AgentClient

load_dotenv()


class OpenAICUAClient(AgentClient):
    def __init__(
        self,
        model: str = "gpt-4o",
        instructions: Optional[str] = None,  # System prompt
        config: Optional[AgentConfig] = None,
        logger: Optional[Any] = None,
        handler: Optional[CUAHandler] = None,
        viewport: Optional[dict[str, int]] = None,
        **kwargs,  # Allow for other OpenAI specific options if any
    ):
        super().__init__(model, instructions, config, logger, handler)
        # TODO pass api key
        api_key = (
            config.options.get("apiKey")
            if config and config.options
            else os.getenv("OPENAI_API_KEY")
        )
        base_url = None
        if config and config.options:
            base_url = config.options.get("baseURL") or config.options.get("api_base")

        self.logger.info(
            f"OpenAI client config - api_key: {api_key[:10] if api_key else None}..., base_url: {base_url}"
        )

        self.openai_sdk_client = OpenAISDK(api_key=api_key, base_url=base_url)

        self.tools = [
            {
                "type": "function",
                "name": "goto",
                "description": "Navigate to a specific URL",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "url": {
                            "type": "string",
                            "description": (
                                "The URL to navigate to. Provide a full URL, including the protocol (e.g., https://www.google.com)."
                            ),
                        },
                    },
                    "required": ["url"],
                },
            },
        ]

    def format_screenshot(self, screenshot_base64: str) -> dict:
        """Formats a screenshot for the OpenAI CUA model."""
        return {
            "type": "input_image",
            "image_url": f"data:image/png;base64,{screenshot_base64}",
        }

    def _format_initial_messages(
        self, instruction: str, screenshot_base64: Optional[str]
    ) -> list[Any]:
        messages: list[Any] = []
        if self.instructions:  # System prompt from AgentConfig.instructions
            messages.append({"role": "system", "content": self.instructions})

        user_content: list[Any] = [{"type": "input_text", "text": instruction}]
        if screenshot_base64:
            user_content.append(self.format_screenshot(screenshot_base64))
        messages.append({"role": "user", "content": user_content})
        return messages

    def _process_provider_response(
        self, response: Any
    ) -> tuple[Optional[AgentAction], Optional[str], bool, Optional[str]]:
        if not response.output:
            self.logger.error(
                "No output from OpenAI model in response object", category="agent"
            )
            return (
                None,
                "Error: No output from model",
                True,
                "Error: No output from model",
            )

        output_items = response.output

        function_call_item = next(
            (item for item in output_items if item.type == "function_call"), None
        )
        reasoning_item = next(
            (item for item in output_items if item.type == "reasoning"), None
        )
        message_item = next(
            (item for item in output_items if item.type == "message"), None
        )

        reasoning_text = None
        if (
            reasoning_item
            and reasoning_item.summary
            and isinstance(reasoning_item.summary, list)
            and len(reasoning_item.summary) > 0
        ):
            reasoning_text = reasoning_item.summary[0].text

        final_model_message = None
        if (
            message_item
            and message_item.content
            and isinstance(message_item.content, list)
        ):
            final_model_message_parts = [
                content_item.text
                for content_item in message_item.content
                if hasattr(content_item, "text") and content_item.type == "output_text"
            ]
            if final_model_message_parts:
                final_model_message = " ".join(final_model_message_parts)

        agent_action: Optional[AgentAction] = None

        if function_call_item:
            try:
                arguments = (
                    json.loads(function_call_item.arguments)
                    if isinstance(function_call_item.arguments, str)
                    else function_call_item.arguments
                )
                # Ensure arguments is a dict, even if empty
                if not isinstance(arguments, dict):
                    self.logger.debug(
                        f"Function call arguments are not a dict: {arguments}. Using empty dict.",
                        category="agent",
                    )
                    arguments = {}

                function_action_payload = FunctionAction(
                    type="function", name=function_call_item.name, arguments=arguments
                )  # type: ignore
                agent_action = AgentAction(
                    action_type="function",  # Literal 'function'
                    action=AgentActionType(root=function_action_payload),
                    reasoning=reasoning_text,  # Reasoning applies to this action
                    status=(
                        function_call_item.status
                        if hasattr(function_call_item, "status")
                        else "in_progress"
                    ),  # function_call might not have status
                    step=[item.model_dump() for item in output_items],
                )
                return agent_action, reasoning_text, False, final_model_message
            except json.JSONDecodeError as e_json:
                self.logger.error(
                    f"JSONDecodeError for function_call arguments: {function_call_item.arguments}. Error: {e_json}",
                    category="agent",
                )
                return (
                    None,
                    reasoning_text,
                    True,
                    f"Error: Invalid JSON arguments for function call {function_call_item.name}",
                )
            except Exception as e_parse_fn:
                self.logger.error(
                    f"Error parsing function_call_item: {e_parse_fn}", category="agent"
                )
                return (
                    None,
                    reasoning_text,
                    True,
                    f"Error: Failed to parse function_call action: {e_parse_fn}",
                )

        # If no function_call, the task might be complete or just a message/reasoning turn.
        task_complete_reason = (
            final_model_message
            if final_model_message
            else "No further actions from model."
        )
        if (
            not final_model_message and reasoning_text and not agent_action
        ):  # If only reasoning, it's not task completion by message
            task_complete_reason = "Model provided reasoning but no executable action."
        self.logger.info(
            f"OpenAI CUA: Task appears complete or requires user input. Reason: {task_complete_reason}",
            category="agent",
        )
        return None, reasoning_text, True, final_model_message

    def _format_action_feedback(
        self,
        action_type_performed: str,
        call_id_performed: str,
        action_result: ActionExecutionResult,
    ) -> list[Any]:
        if not call_id_performed:
            self.logger.error(
                "Missing call_id for formatting action feedback.", category="agent"
            )
            return [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_text",
                            "text": (
                                "Error: Internal error, missing call_id for feedback."
                            ),
                        }
                    ],
                }
            ]

        output_item_type = "function_call_output"

        output_payload: Any
        if action_result["success"]:
            # Function results are often simple strings or JSON strings.
            output_payload = json.dumps(
                {
                    "status": "success",
                    "detail": f"Function {action_type_performed} executed.",
                }
            )
        else:
            error_message = f"Action {action_type_performed} failed: {action_result.get('error', 'Unknown error')}"
            self.logger.info(
                f"Formatting failed action feedback for OpenAI: {error_message}",
                category="agent",
            )
            output_payload = json.dumps({"status": "error", "detail": error_message})

        return [
            {
                "type": output_item_type,
                "call_id": call_id_performed,
                "output": output_payload,
            }
        ]

    async def run_task(
        self,
        instruction: str,
        max_steps: int = 20,
        options: Optional[AgentExecuteOptions] = None,
    ) -> AgentResult:
        self.logger.debug(
            f"OpenAI CUA starting task: '{instruction}' with max_steps: {max_steps}",
            category="agent",
        )

        if not self.handler:
            self.logger.error(
                "CUAHandler not available for OpenAIClient.", category="agent"
            )
            return AgentResult(
                completed=False,
                actions=[],
                message="Internal error: Handler not set.",
                usage={"input_tokens": 0, "output_tokens": 0, "inference_time_ms": 0},
            )

        await self.handler.inject_cursor()
        current_screenshot_b64 = await self.handler.get_screenshot_base64()

        current_input_items: list[Any] = self._format_initial_messages(
            instruction, current_screenshot_b64
        )

        actions_taken: list[AgentAction] = []
        total_input_tokens = 0
        total_output_tokens = 0
        total_inference_time_ms = 0  # Placeholder

        for step_count in range(max_steps):
            self.logger.info(
                f"OpenAI CUA - Step {step_count + 1}/{max_steps}",
                category="agent",
            )

            start_time = asyncio.get_event_loop().time()
            try:
                # ä½¿ç”¨æ ‡å‡†çš„ Chat Completions API è€Œä¸æ˜¯ Computer Use API
                # å°†æ¶ˆæ¯æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼

                messages = []
                for item in current_input_items:
                    if isinstance(item, dict):
                        if item.get("role") == "system":
                            messages.append(
                                {"role": "system", "content": item.get("content", "")}
                            )
                        elif item.get("role") == "user":
                            content = item.get("content", [])
                            if isinstance(content, list):
                                # å¤„ç†å¤šæ¨¡æ€å†…å®¹
                                user_content = []
                                for c in content:
                                    if c.get("type") == "input_text":
                                        user_content.append(
                                            {"type": "text", "text": c.get("text", "")}
                                        )
                                    elif c.get("type") == "input_image":
                                        # ä» format_screenshot æ–¹æ³•è¿”å›çš„æ ¼å¼ä¸­æå– image_url
                                        image_url = c.get("image_url", "")
                                        user_content.append(
                                            {
                                                "type": "image_url",
                                                "image_url": {"url": image_url},
                                            }
                                        )

                                messages.append(
                                    {"role": "user", "content": user_content}
                                )
                            else:
                                messages.append({"role": "user", "content": content})

                # å¦‚æœæ²¡æœ‰æ¶ˆæ¯ï¼Œæ·»åŠ ä¸€ä¸ªé»˜è®¤æ¶ˆæ¯
                if not messages:
                    messages = [
                        {"role": "user", "content": "è¯·åˆ†æå½“å‰é¡µé¢å¹¶æ‰§è¡ŒæŒ‡å®šä»»åŠ¡"}
                    ]

                response = self.openai_sdk_client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=1000,
                )
                print("--------------------------------")
                print(response)
                end_time = asyncio.get_event_loop().time()
                total_inference_time_ms += int((end_time - start_time) * 1000)

                # å¤„ç†æ™ºè°±AIçš„usageå­—æ®µå·®å¼‚
                if hasattr(response, "usage") and response.usage:
                    # æ™ºè°±AIå¯èƒ½ä½¿ç”¨ä¸åŒçš„å­—æ®µå
                    input_tokens = getattr(
                        response.usage, "input_tokens", None
                    ) or getattr(response.usage, "prompt_tokens", 0)
                    output_tokens = getattr(
                        response.usage, "output_tokens", None
                    ) or getattr(response.usage, "completion_tokens", 0)
                    total_input_tokens += input_tokens
                    total_output_tokens += output_tokens
                    self.logger.info(
                        f"Token usage - input: {input_tokens}, output: {output_tokens}"
                    )

            except Exception as e:
                self.logger.error(f"OpenAI API call failed: {e}", category="agent")
                # Ensure usage is a valid AgentUsage object or None
                usage_obj = {
                    "input_tokens": total_input_tokens,
                    "output_tokens": total_output_tokens,
                    "inference_time_ms": total_inference_time_ms,
                }
                return AgentResult(
                    actions=[act.action for act in actions_taken if act.action],
                    message=f"OpenAI API error: {e}",
                    completed=True,
                    usage=usage_obj,
                )

            # å¤„ç†æ ‡å‡† Chat Completions å“åº”
            if response.choices and response.choices[0].message:
                message_content = response.choices[0].message.content
                self.logger.info(f"GLM API response: {message_content}")

                # è§£æå“åº”ä¸­çš„æ“ä½œæŒ‡ä»¤
                agent_action = self._parse_action_from_response(message_content)

                if agent_action:
                    # æ‰§è¡Œè§£æå‡ºçš„æ“ä½œ
                    self.logger.info(f"Executing action: {agent_action.action_type}")

                    # ğŸ”§ GLM-4.5Våæ ‡è½¬æ¢ï¼šåƒåˆ†æ¯” â†’ åƒç´ åæ ‡
                    if (
                        agent_action.action_type == "click"
                        and hasattr(agent_action, "action")
                        and agent_action.action
                        and hasattr(agent_action.action.root, "x")
                        and hasattr(agent_action.action.root, "y")
                    ):
                        # è·å–è§†å£å°ºå¯¸
                        viewport = self.handler.page.viewport_size
                        viewport_width = viewport["width"]
                        viewport_height = viewport["height"]

                        # GLM-4.5Vè¿”å›çš„æ˜¯åƒåˆ†æ¯”åæ ‡ï¼Œéœ€è¦è½¬æ¢ä¸ºå®é™…åƒç´ 
                        glm_x = agent_action.action.root.x
                        glm_y = agent_action.action.root.y

                        # è½¬æ¢å…¬å¼ï¼šåƒåˆ†æ¯” â†’ å®é™…åƒç´ åæ ‡
                        actual_x = int((glm_x / 1000) * viewport_width)
                        actual_y = int((glm_y / 1000) * viewport_height)

                        self.logger.info(
                            f"GLM-4.5Våæ ‡è½¬æ¢: åƒåˆ†æ¯”({glm_x}, {glm_y}) â†’ åƒç´ ({actual_x}, {actual_y})"
                        )
                        self.logger.info(
                            f"è§†å£å°ºå¯¸: {viewport_width}x{viewport_height}"
                        )

                        # æ›´æ–°åæ ‡
                        agent_action.action.root.x = actual_x
                        agent_action.action.root.y = actual_y

                    action_result = await self.handler.perform_action(agent_action)
                    actions_taken.append(agent_action)

                    # è·å–æ‰§è¡Œåçš„æ–°æˆªå›¾
                    new_screenshot_b64 = await self.handler.get_screenshot_base64()

                    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­
                    if action_result.get("success", False):
                        # å¦‚æœæ“ä½œæˆåŠŸä¸”åªæœ‰ä¸€æ­¥ï¼Œå¯ä»¥æ ‡è®°ä¸ºå®Œæˆ
                        task_completed = True
                    else:
                        # æ“ä½œå¤±è´¥ï¼Œç»§ç»­å°è¯•
                        current_input_items = [
                            {
                                "role": "user",
                                "content": [
                                    {
                                        "type": "input_text",
                                        "text": f"Previous action failed: {action_result.get('error', 'Unknown error')}. Please try a different approach.",
                                    },
                                    self.format_screenshot(new_screenshot_b64),
                                ],
                            }
                        ]
                        continue
                else:
                    # æ²¡æœ‰è§£æåˆ°æ“ä½œï¼Œæ ‡è®°ä¸ºå®Œæˆ
                    task_completed = True

                if task_completed:
                    return AgentResult(
                        actions=[act.action for act in actions_taken if act.action],
                        message=message_content or "Task completed successfully",
                        completed=True,
                        usage={
                            "input_tokens": total_input_tokens,
                            "output_tokens": total_output_tokens,
                            "inference_time_ms": total_inference_time_ms,
                        },
                    )
            else:
                self.logger.error("No response from GLM API")
                return AgentResult(
                    actions=[],
                    message="No response from GLM API",
                    completed=True,
                    usage={
                        "input_tokens": total_input_tokens,
                        "output_tokens": total_output_tokens,
                        "inference_time_ms": total_inference_time_ms,
                    },
                )

        self.logger.info("Max steps reached for OpenAI CUA task.", category="agent")
        usage_obj = {
            "input_tokens": total_input_tokens,
            "output_tokens": total_output_tokens,
            "inference_time_ms": total_inference_time_ms,
        }
        return AgentResult(
            actions=[act.action for act in actions_taken if act.action],
            message="Max steps reached.",
            completed=False,
            usage=usage_obj,
        )

    def _parse_action_from_response(
        self, message_content: str
    ) -> Optional[AgentAction]:
        """è§£æGLMå“åº”ä¸­çš„æ“ä½œæŒ‡ä»¤"""
        import re
        from ..types.agent import (
            ClickAction,
            TypeAction,
            ScrollAction,
            WaitAction,
            AgentActionType,
        )

        if not message_content:
            return None

        message_content = message_content.strip()

        # è§£æç‚¹å‡»æŒ‡ä»¤: "CLICK: x=150, y=200"
        click_pattern = r"CLICK:\s*x\s*=\s*(\d+)\s*,\s*y\s*=\s*(\d+)"
        click_match = re.search(click_pattern, message_content, re.IGNORECASE)
        if click_match:
            x, y = int(click_match.group(1)), int(click_match.group(2))
            click_action = ClickAction(type="click", x=x, y=y, button="left")
            return AgentAction(
                action_type="click",
                action=AgentActionType(root=click_action),
                reasoning=f"Clicking at coordinates ({x}, {y})",
            )

        # è§£æè¾“å…¥æŒ‡ä»¤: "TYPE: text=hello world" æˆ– "TYPE: x=100, y=200, text=hello world"
        type_pattern_with_coords = (
            r"TYPE:\s*x\s*=\s*(\d+)\s*,\s*y\s*=\s*(\d+)\s*,\s*text\s*=\s*(.+?)(?:\n|$)"
        )
        type_match_with_coords = re.search(
            type_pattern_with_coords, message_content, re.IGNORECASE
        )
        if type_match_with_coords:
            x, y, text = (
                int(type_match_with_coords.group(1)),
                int(type_match_with_coords.group(2)),
                type_match_with_coords.group(3).strip(),
            )

            # ğŸ”§ GLM-4.5Våæ ‡è½¬æ¢ï¼šåƒåˆ†æ¯” â†’ åƒç´ åæ ‡
            viewport = self.handler.page.viewport_size
            viewport_width = viewport["width"]
            viewport_height = viewport["height"]

            # GLM-4.5Vè¿”å›çš„æ˜¯åƒåˆ†æ¯”åæ ‡ï¼Œéœ€è¦è½¬æ¢ä¸ºå®é™…åƒç´ 
            actual_x = int((x / 1000) * viewport_width)
            actual_y = int((y / 1000) * viewport_height)

            self.logger.info(
                f"GLM-4.5V TYPEåæ ‡è½¬æ¢: åƒåˆ†æ¯”({x}, {y}) â†’ åƒç´ ({actual_x}, {actual_y})"
            )

            # ğŸ§¹ æ¸…ç†GLM-4.5Vå“åº”ä¸­çš„ç‰¹æ®Šæ ‡è®°
            clean_text = self._clean_glm_response_text(text)

            type_action = TypeAction(
                type="type", text=clean_text, x=actual_x, y=actual_y
            )
            return AgentAction(
                action_type="type",
                action=AgentActionType(root=type_action),
                reasoning=f"Typing text '{clean_text}' at coordinates ({actual_x}, {actual_y})",
            )

        # è§£æç®€å•è¾“å…¥æŒ‡ä»¤: "TYPE: text=hello world" (ä¸å¸¦åæ ‡)
        type_pattern = r"TYPE:\s*text\s*=\s*(.+?)(?:\n|$)"
        type_match = re.search(type_pattern, message_content, re.IGNORECASE)
        if type_match:
            text = type_match.group(1).strip()
            # ğŸ§¹ æ¸…ç†GLM-4.5Vå“åº”ä¸­çš„ç‰¹æ®Šæ ‡è®°
            clean_text = self._clean_glm_response_text(text)

            type_action = TypeAction(type="type", text=clean_text)
            return AgentAction(
                action_type="type",
                action=AgentActionType(root=type_action),
                reasoning=f"Typing text: {clean_text}",
            )

        # è§£ææ»šåŠ¨æŒ‡ä»¤: "SCROLL: x=500, y=300, scroll_y=-100"
        scroll_pattern = r"SCROLL:\s*x\s*=\s*(\d+)\s*,\s*y\s*=\s*(\d+)(?:\s*,\s*scroll_x\s*=\s*([+-]?\d+))?\s*(?:\s*,\s*scroll_y\s*=\s*([+-]?\d+))?"
        scroll_match = re.search(scroll_pattern, message_content, re.IGNORECASE)
        if scroll_match:
            x, y = int(scroll_match.group(1)), int(scroll_match.group(2))
            scroll_x = int(scroll_match.group(3)) if scroll_match.group(3) else 0
            scroll_y = int(scroll_match.group(4)) if scroll_match.group(4) else 0
            scroll_action = ScrollAction(
                type="scroll", x=x, y=y, scroll_x=scroll_x, scroll_y=scroll_y
            )
            return AgentAction(
                action_type="scroll",
                action=AgentActionType(root=scroll_action),
                reasoning=f"Scrolling at ({x}, {y}) with scroll_x={scroll_x}, scroll_y={scroll_y}",
            )

        # è§£æç­‰å¾…æŒ‡ä»¤: "WAIT: milliseconds=2000"
        wait_pattern = r"WAIT:\s*milliseconds\s*=\s*(\d+)"
        wait_match = re.search(wait_pattern, message_content, re.IGNORECASE)
        if wait_match:
            milliseconds = int(wait_match.group(1))
            wait_action = WaitAction(type="wait", miliseconds=milliseconds)
            return AgentAction(
                action_type="wait",
                action=AgentActionType(root=wait_action),
                reasoning=f"Waiting for {milliseconds} milliseconds",
            )

        # å¢å¼ºè§£æï¼šå¤„ç†GLM-4.5Vå¯èƒ½çš„å„ç§å“åº”æ ¼å¼

        # 1. ä»è‡ªç„¶è¯­è¨€ä¸­æå–ç‚¹å‡»åæ ‡
        coord_patterns = [
            r"(?:ç‚¹å‡»|click).*?(?:åæ ‡|coordinates?).*?[(\[]?\s*(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[)\]]?",
            r"[(\[]?\s*(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[)\]]?.*?(?:ç‚¹å‡»|click)",
            r"x\s*[:=]\s*(\d+).*?y\s*[:=]\s*(\d+)",
            r"ä½ç½®\s*[(\[]?\s*(\d+)\s*[,ï¼Œ]\s*(\d+)\s*[)\]]?",
        ]

        for pattern in coord_patterns:
            coord_match = re.search(pattern, message_content, re.IGNORECASE)
            if coord_match:
                x, y = int(coord_match.group(1)), int(coord_match.group(2))
                click_action = ClickAction(type="click", x=x, y=y, button="left")
                return AgentAction(
                    action_type="click",
                    action=AgentActionType(root=click_action),
                    reasoning=f"Extracted click coordinates from natural language: ({x}, {y})",
                )

        # 2. å¦‚æœGLMè¿”å›äº†æè¿°æ€§æ–‡å­—ï¼Œå°è¯•æ™ºèƒ½æ¨æ–­æ“ä½œ
        # æ£€æŸ¥æ˜¯å¦æåˆ°äº†ç‚¹å‡»æ“ä½œ
        if re.search(r"ç‚¹å‡»|click", message_content, re.IGNORECASE):
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´æ™ºèƒ½çš„åæ ‡æ¨æ–­é€»è¾‘
            # æš‚æ—¶è¿”å›Noneï¼Œè®©ç³»ç»Ÿæç¤ºGLMè¿”å›æ­£ç¡®æ ¼å¼
            self.logger.warning(
                f"GLM returned descriptive text instead of action command: {message_content}"
            )
            self.logger.warning(
                "Please check if the system prompt is correctly instructing GLM to return action commands"
            )

        # 3. æ£€æŸ¥æ˜¯å¦æåˆ°äº†è¾“å…¥æ“ä½œ
        if re.search(r"è¾“å…¥|input|type", message_content, re.IGNORECASE):
            # å°è¯•æå–è¦è¾“å…¥çš„æ–‡æœ¬
            input_patterns = [
                r"è¾“å…¥[\"']([^\"']+)[\"']",
                r"è¾“å…¥\s*[:ï¼š]\s*([^\n]+)",
                r"type\s*[:ï¼š]\s*([^\n]+)",
            ]

            for pattern in input_patterns:
                input_match = re.search(pattern, message_content, re.IGNORECASE)
                if input_match:
                    text = input_match.group(1).strip()
                    type_action = TypeAction(type="type", text=text)
                    return AgentAction(
                        action_type="type",
                        action=AgentActionType(root=type_action),
                        reasoning=f"Extracted text input from natural language: {text}",
                    )

        return None

    def _clean_glm_response_text(self, text: str) -> str:
        """
        æ¸…ç†GLM-4.5Vå“åº”ä¸­çš„ç‰¹æ®Šæ ‡è®°
        ç§»é™¤å¦‚ <|end_of_box|>ã€<|start_of_box|> ç­‰æ ‡è®°
        """
        if not text:
            return text

        # å®šä¹‰éœ€è¦æ¸…ç†çš„GLMç‰¹æ®Šæ ‡è®°æ¨¡å¼
        glm_markers = [
            r"<\|end_of_box\|>",
            r"<\|start_of_box\|>",
            r"<\|end_of_text\|>",
            r"<\|start_of_text\|>",
            r"<\|.*?\|>",  # é€šç”¨çš„GLMæ ‡è®°æ¨¡å¼
        ]

        clean_text = text
        for pattern in glm_markers:
            clean_text = re.sub(pattern, "", clean_text, flags=re.IGNORECASE)

        # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
        clean_text = clean_text.strip()

        if clean_text != text:
            self.logger.info(f"ğŸ§¹ æ¸…ç†GLMå“åº”æ–‡æœ¬: '{text}' â†’ '{clean_text}'")

        return clean_text

    def key_to_playwright(self, key: str) -> str:
        """Converts a key name if OpenAI CUA uses specific names not covered by CUAHandler."""
        return key
