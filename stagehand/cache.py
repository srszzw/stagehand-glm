"""
Stagehand ç¼“å­˜ç®¡ç†å™¨
æä¾›æ™ºèƒ½ç¼“å­˜åŠŸèƒ½ï¼Œå‡å°‘LLMè°ƒç”¨ï¼Œæå‡æ€§èƒ½
"""

import json
import hashlib
import time
import os
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
import asyncio

from .schemas import ObserveResult
from .logging import StagehandLogger


class StagehandCache:
    """Stagehand ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(
        self,
        cache_file: str = "stagehand_cache.json",
        logger: Optional[StagehandLogger] = None,
    ):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨

        Args:
            cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„
            logger: æ—¥å¿—è®°å½•å™¨
        """
        self.cache_file = cache_file
        self.logger = logger
        self.cache_data = self._load_cache()
        self._memory_cache = {}  # å†…å­˜ç¼“å­˜ï¼Œæå‡æ€§èƒ½

    def _load_cache(self) -> Dict[str, Any]:
        """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if self.logger:
                        self.logger.info(
                            f"âœ… åŠ è½½ç¼“å­˜æ–‡ä»¶æˆåŠŸï¼ŒåŒ…å« {len(data.get('caches', {}))} æ¡è®°å½•"
                        )
                    return data
        except Exception as e:
            if self.logger:
                self.logger.warning(f"âš ï¸ åŠ è½½ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")

        # è¿”å›é»˜è®¤ç¼“å­˜ç»“æ„
        return {
            "version": "1.0",
            "created_at": datetime.now().isoformat(),
            "caches": {},
        }

    def _save_cache(self) -> None:
        """ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶"""
        try:
            self.cache_data["last_updated"] = datetime.now().isoformat()
            with open(self.cache_file, "w", encoding="utf-8") as f:
                json.dump(self.cache_data, f, ensure_ascii=False, indent=2)
            if self.logger:
                self.logger.debug("ğŸ’¾ ç¼“å­˜æ–‡ä»¶ä¿å­˜æˆåŠŸ")
        except Exception as e:
            if self.logger:
                self.logger.error(f"âŒ ä¿å­˜ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")

    def _generate_cache_key(
        self, instruction: str, page_url: str, page_title: str = None
    ) -> str:
        """
        ç”Ÿæˆç¼“å­˜key

        Args:
            instruction: ç”¨æˆ·æŒ‡ä»¤
            page_url: é¡µé¢URL
            page_title: é¡µé¢æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰

        Returns:
            ç¼“å­˜keyçš„å“ˆå¸Œå€¼
        """
        # åˆ›å»ºå¤åˆkey
        key_components = {
            "instruction": instruction.strip().lower(),
            "page_url": page_url,
            "page_title": page_title or "",
        }

        # ç”Ÿæˆå“ˆå¸Œ
        key_string = json.dumps(key_components, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(key_string.encode("utf-8")).hexdigest()

    def get_cached_result(
        self, instruction: str, page_url: str, page_title: str = None, ttl: int = 3600
    ) -> Optional[ObserveResult]:
        """
        è·å–ç¼“å­˜çš„è§‚å¯Ÿç»“æœ

        Args:
            instruction: ç”¨æˆ·æŒ‡ä»¤
            page_url: é¡µé¢URL
            page_title: é¡µé¢æ ‡é¢˜
            ttl: ç¼“å­˜ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            ç¼“å­˜çš„ObserveResultæˆ–None
        """
        cache_key = self._generate_cache_key(instruction, page_url, page_title)

        # å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
        if cache_key in self._memory_cache:
            cached_item = self._memory_cache[cache_key]
            if self._is_cache_valid(cached_item, ttl):
                if self.logger:
                    self.logger.info(f"ğŸš€ å†…å­˜ç¼“å­˜å‘½ä¸­: {instruction[:50]}...")
                self._update_cache_stats(cache_key, hit=True)
                return self._create_observe_result_from_cache(cached_item["result"])

        # æ£€æŸ¥æ–‡ä»¶ç¼“å­˜
        caches = self.cache_data.get("caches", {})
        if cache_key in caches:
            cached_item = caches[cache_key]
            if self._is_cache_valid(cached_item, ttl):
                if self.logger:
                    self.logger.info(f"ğŸ“ æ–‡ä»¶ç¼“å­˜å‘½ä¸­: {instruction[:50]}...")

                # åŠ è½½åˆ°å†…å­˜ç¼“å­˜
                self._memory_cache[cache_key] = cached_item
                self._update_cache_stats(cache_key, hit=True)
                return self._create_observe_result_from_cache(cached_item["result"])
            else:
                # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                if self.logger:
                    self.logger.info(f"â° ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤: {instruction[:50]}...")
                del caches[cache_key]
                self._save_cache()

        if self.logger:
            self.logger.debug(f"âŒ ç¼“å­˜æœªå‘½ä¸­: {instruction[:50]}...")
        return None

    def set_cache(
        self,
        instruction: str,
        page_url: str,
        result: ObserveResult,
        page_title: str = None,
    ) -> None:
        """
        è®¾ç½®ç¼“å­˜

        Args:
            instruction: ç”¨æˆ·æŒ‡ä»¤
            page_url: é¡µé¢URL
            result: ObserveResultç»“æœ
            page_title: é¡µé¢æ ‡é¢˜
        """
        cache_key = self._generate_cache_key(instruction, page_url, page_title)

        cache_item = {
            "instruction": instruction,
            "page_url": page_url,
            "page_title": page_title or "",
            "result": {
                "selector": result.selector,
                "description": result.description,
                "method": result.method,
                "arguments": result.arguments,
                "backend_node_id": result.backend_node_id,
            },
            "created_at": datetime.now().isoformat(),
            "last_used": datetime.now().isoformat(),
            "hit_count": 0,
        }

        # ä¿å­˜åˆ°å†…å­˜å’Œæ–‡ä»¶ç¼“å­˜
        self._memory_cache[cache_key] = cache_item
        self.cache_data["caches"][cache_key] = cache_item
        self._save_cache()

        if self.logger:
            self.logger.info(f"ğŸ’¾ ç¼“å­˜å·²ä¿å­˜: {instruction[:50]}...")

    def _is_cache_valid(self, cached_item: Dict[str, Any], ttl: int) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        try:
            created_at = datetime.fromisoformat(cached_item["created_at"])
            return datetime.now() - created_at < timedelta(seconds=ttl)
        except:
            return False

    def _create_observe_result_from_cache(
        self, cached_result: Dict[str, Any]
    ) -> ObserveResult:
        """ä»ç¼“å­˜æ•°æ®åˆ›å»ºObserveResultå¯¹è±¡"""
        return ObserveResult(
            selector=cached_result["selector"],
            description=cached_result["description"],
            method=cached_result.get("method"),
            arguments=cached_result.get("arguments"),
            backend_node_id=cached_result.get("backend_node_id"),
        )

    def _update_cache_stats(self, cache_key: str, hit: bool = True) -> None:
        """æ›´æ–°ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        # æ›´æ–°å†…å­˜ç¼“å­˜ç»Ÿè®¡
        if cache_key in self._memory_cache:
            if hit:
                self._memory_cache[cache_key]["hit_count"] += 1
                self._memory_cache[cache_key]["last_used"] = datetime.now().isoformat()

        # æ›´æ–°æ–‡ä»¶ç¼“å­˜ç»Ÿè®¡
        caches = self.cache_data.get("caches", {})
        if cache_key in caches:
            if hit:
                caches[cache_key]["hit_count"] += 1
                caches[cache_key]["last_used"] = datetime.now().isoformat()

    async def validate_cached_xpath(self, page, xpath: str) -> bool:
        """
        éªŒè¯ç¼“å­˜çš„xpathæ˜¯å¦ä»ç„¶æœ‰æ•ˆ

        Args:
            page: StagehandPageå®ä¾‹
            xpath: è¦éªŒè¯çš„xpath

        Returns:
            xpathæ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # ç§»é™¤xpath=å‰ç¼€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            clean_xpath = xpath.replace("xpath=", "")

            # å°è¯•å®šä½å…ƒç´ 
            locator = page._page.locator(f"xpath={clean_xpath}").first

            # æ£€æŸ¥å…ƒç´ æ˜¯å¦å­˜åœ¨
            count = await locator.count()
            return count > 0

        except Exception as e:
            if self.logger:
                self.logger.debug(f"XPathéªŒè¯å¤±è´¥: {xpath}, é”™è¯¯: {e}")
            return False

    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        caches = self.cache_data.get("caches", {})
        total_caches = len(caches)
        total_hits = sum(cache.get("hit_count", 0) for cache in caches.values())

        # è®¡ç®—å†…å­˜ç¼“å­˜å¤§å°
        memory_cache_size = len(self._memory_cache)

        return {
            "total_caches": total_caches,
            "total_hits": total_hits,
            "memory_cache_size": memory_cache_size,
            "cache_file": self.cache_file,
            "version": self.cache_data.get("version", "unknown"),
        }

    def clear_cache(self, expired_only: bool = False, ttl: int = 3600) -> int:
        """
        æ¸…ç†ç¼“å­˜

        Args:
            expired_only: æ˜¯å¦åªæ¸…ç†è¿‡æœŸçš„ç¼“å­˜
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            æ¸…ç†çš„ç¼“å­˜æ•°é‡
        """
        cleared_count = 0
        caches = self.cache_data.get("caches", {})

        if expired_only:
            # åªæ¸…ç†è¿‡æœŸç¼“å­˜
            expired_keys = []
            for key, cached_item in caches.items():
                if not self._is_cache_valid(cached_item, ttl):
                    expired_keys.append(key)

            for key in expired_keys:
                del caches[key]
                if key in self._memory_cache:
                    del self._memory_cache[key]
                cleared_count += 1
        else:
            # æ¸…ç†æ‰€æœ‰ç¼“å­˜
            cleared_count = len(caches)
            caches.clear()
            self._memory_cache.clear()

        if cleared_count > 0:
            self._save_cache()
            if self.logger:
                self.logger.info(f"ğŸ§¹ å·²æ¸…ç† {cleared_count} æ¡ç¼“å­˜è®°å½•")

        return cleared_count
